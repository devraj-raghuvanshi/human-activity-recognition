{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.read_csv('../data/final_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>label</th>\n",
       "      <th>back_x_mean</th>\n",
       "      <th>back_x_std</th>\n",
       "      <th>back_x_skew</th>\n",
       "      <th>back_x_kurt</th>\n",
       "      <th>back_x_max</th>\n",
       "      <th>back_x_zero_crossings</th>\n",
       "      <th>...</th>\n",
       "      <th>thigh_y_skew</th>\n",
       "      <th>thigh_y_kurt</th>\n",
       "      <th>thigh_y_rms</th>\n",
       "      <th>thigh_y_zero_crossings</th>\n",
       "      <th>thigh_z_mean</th>\n",
       "      <th>thigh_z_skew</th>\n",
       "      <th>thigh_z_kurt</th>\n",
       "      <th>thigh_z_max</th>\n",
       "      <th>thigh_z_rms</th>\n",
       "      <th>thigh_z_zero_crossings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>walking</td>\n",
       "      <td>-0.975977</td>\n",
       "      <td>0.137209</td>\n",
       "      <td>0.553341</td>\n",
       "      <td>16.817742</td>\n",
       "      <td>-0.355071</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.686721</td>\n",
       "      <td>32.951507</td>\n",
       "      <td>0.130952</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.272417</td>\n",
       "      <td>4.569072</td>\n",
       "      <td>30.871566</td>\n",
       "      <td>0.709439</td>\n",
       "      <td>0.304457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>149</td>\n",
       "      <td>walking</td>\n",
       "      <td>-0.989042</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>-0.099840</td>\n",
       "      <td>-0.245041</td>\n",
       "      <td>-0.976182</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987363</td>\n",
       "      <td>0.877986</td>\n",
       "      <td>0.057976</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.296721</td>\n",
       "      <td>-0.098355</td>\n",
       "      <td>-0.948189</td>\n",
       "      <td>-0.278594</td>\n",
       "      <td>0.296813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>walking</td>\n",
       "      <td>-0.989415</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>-0.688959</td>\n",
       "      <td>1.025675</td>\n",
       "      <td>-0.968303</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.364330</td>\n",
       "      <td>5.971838</td>\n",
       "      <td>0.069254</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.300218</td>\n",
       "      <td>-1.503124</td>\n",
       "      <td>3.112805</td>\n",
       "      <td>-0.277551</td>\n",
       "      <td>0.300466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>249</td>\n",
       "      <td>walking</td>\n",
       "      <td>-1.001666</td>\n",
       "      <td>0.089329</td>\n",
       "      <td>-1.872917</td>\n",
       "      <td>6.356036</td>\n",
       "      <td>-0.802925</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.249045</td>\n",
       "      <td>5.896466</td>\n",
       "      <td>0.162145</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.296553</td>\n",
       "      <td>0.976161</td>\n",
       "      <td>6.404589</td>\n",
       "      <td>0.553839</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>299</td>\n",
       "      <td>inactive</td>\n",
       "      <td>-0.994725</td>\n",
       "      <td>0.093550</td>\n",
       "      <td>-1.814825</td>\n",
       "      <td>5.336248</td>\n",
       "      <td>-0.802925</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589514</td>\n",
       "      <td>2.207475</td>\n",
       "      <td>0.183160</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.235579</td>\n",
       "      <td>0.067203</td>\n",
       "      <td>1.885965</td>\n",
       "      <td>0.553839</td>\n",
       "      <td>0.315772</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  window_start  window_end     label  back_x_mean  back_x_std  \\\n",
       "0           1             0          99   walking    -0.975977    0.137209   \n",
       "1           1            50         149   walking    -0.989042    0.006359   \n",
       "2           1           100         199   walking    -0.989415    0.008734   \n",
       "3           1           150         249   walking    -1.001666    0.089329   \n",
       "4           1           200         299  inactive    -0.994725    0.093550   \n",
       "\n",
       "   back_x_skew  back_x_kurt  back_x_max  back_x_zero_crossings  ...  \\\n",
       "0     0.553341    16.817742   -0.355071                      0  ...   \n",
       "1    -0.099840    -0.245041   -0.976182                      0  ...   \n",
       "2    -0.688959     1.025675   -0.968303                      0  ...   \n",
       "3    -1.872917     6.356036   -0.802925                      0  ...   \n",
       "4    -1.814825     5.336248   -0.802925                      0  ...   \n",
       "\n",
       "   thigh_y_skew  thigh_y_kurt  thigh_y_rms  thigh_y_zero_crossings  \\\n",
       "0     -4.686721     32.951507     0.130952                      19   \n",
       "1      0.987363      0.877986     0.057976                       0   \n",
       "2      2.364330      5.971838     0.069254                       0   \n",
       "3      1.249045      5.896466     0.162145                       4   \n",
       "4      0.589514      2.207475     0.183160                      14   \n",
       "\n",
       "   thigh_z_mean  thigh_z_skew  thigh_z_kurt  thigh_z_max  thigh_z_rms  \\\n",
       "0     -0.272417      4.569072     30.871566     0.709439     0.304457   \n",
       "1     -0.296721     -0.098355     -0.948189    -0.278594     0.296813   \n",
       "2     -0.300218     -1.503124      3.112805    -0.277551     0.300466   \n",
       "3     -0.296553      0.976161      6.404589     0.553839     0.346667   \n",
       "4     -0.235579      0.067203      1.885965     0.553839     0.315772   \n",
       "\n",
       "   thigh_z_zero_crossings  \n",
       "0                       1  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       4  \n",
       "4                      10  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['back_x_mean', 'back_x_std', 'back_x_skew', 'back_x_kurt', 'back_x_max',\n",
       "       'back_x_zero_crossings', 'back_y_mean', 'back_y_std', 'back_y_skew',\n",
       "       'back_y_kurt', 'back_y_max', 'back_y_min', 'back_y_rms',\n",
       "       'back_y_zero_crossings', 'back_z_mean', 'back_z_skew', 'back_z_kurt',\n",
       "       'back_z_max', 'back_z_min', 'back_z_rms', 'back_z_zero_crossings',\n",
       "       'thigh_x_mean', 'thigh_x_skew', 'thigh_x_kurt', 'thigh_x_max',\n",
       "       'thigh_x_zero_crossings', 'thigh_y_mean', 'thigh_y_skew',\n",
       "       'thigh_y_kurt', 'thigh_y_rms', 'thigh_y_zero_crossings', 'thigh_z_mean',\n",
       "       'thigh_z_skew', 'thigh_z_kurt', 'thigh_z_max', 'thigh_z_rms',\n",
       "       'thigh_z_zero_crossings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.columns[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = df_reduced.columns[4:]\n",
    "X = df_reduced[FEATURES]\n",
    "y = df_reduced['label']\n",
    "groups = np.array(df_reduced['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def group_ml_pipe(X, y, groups, preprocessor, model, param_grid, scoring_metric, num_trials=10, base_random_state=999):\n",
    "    \n",
    "    \"\"\"A function to assemble performance of multiple model runs and optimize\n",
    "    hyperparameters through GridSearchCV with group structure considerations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y : pd.Series\n",
    "        Target variable\n",
    "    groups : pd.Series or np.ndarray\n",
    "        Group labels for the samples\n",
    "    preprocessor : Column transformer object or None\n",
    "        Defines preprocessing on each feature; pass None if not required\n",
    "    model : Initialized model\n",
    "        Machine learning model to be optimized\n",
    "    param_grid : dict\n",
    "        Hyperparameters for the model to be optimized through GridSearchCV\n",
    "    scoring_metric : Scikit-learn scoring function or string\n",
    "        Scoring strategy for GridSearchCV\n",
    "    num_trials : int\n",
    "        Number of iterations to run through to pick optimized parameters\n",
    "    base_random_state : int\n",
    "        Base random seed for reproducibility\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trial_results : list of dicts\n",
    "        Salient information from each GridSearchCV run\n",
    "    \"\"\"\n",
    "    \n",
    "    trial_results = []\n",
    "    \n",
    "    for i in range(1, num_trials + 1):\n",
    "        print(f'Running trial {i}')\n",
    "        random_state = base_random_state * i\n",
    "        \n",
    "        current_trial_info = {\n",
    "            'trial_num': i,\n",
    "            'random_state': random_state\n",
    "        }\n",
    "        \n",
    "        # Separate out the test set\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=random_state)\n",
    "        other_index, test_index = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "        X_other, y_other, groups_other = X.iloc[other_index], y.iloc[other_index], groups[other_index]\n",
    "        X_test, y_test, groups_test = X.iloc[test_index], y.iloc[test_index], groups[test_index]\n",
    "\n",
    "        sgkf = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "        if preprocessor is not None:\n",
    "            pipe = make_pipeline(preprocessor, model)\n",
    "        else:\n",
    "            pipe = make_pipeline(StandardScaler(), model)  # Default scaler if no preprocessor\n",
    "        \n",
    "        # GridSearchCV for hyperparameter optimization\n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid, scoring=scoring_metric,\n",
    "                            cv=sgkf, return_train_score=True, verbose=True, n_jobs=-1)\n",
    "        grid.fit(X_other, y_other, groups=groups_other)\n",
    "        \n",
    "        if grid.scorer_.__dict__['_sign'] < 0:\n",
    "            best_test_score = abs(grid.score(X_test, y_test))\n",
    "            maximized = False\n",
    "        else:\n",
    "            best_test_score = grid.score(X_test, y_test)\n",
    "            maximized = True\n",
    "        \n",
    "        current_trial_info['grid'] = grid\n",
    "        current_trial_info['best_test_score'] = {'score': best_test_score, 'maximized': maximized}\n",
    "        current_trial_info['best_params'] = grid.best_params_\n",
    "        current_trial_info['X_test'] = X_test\n",
    "        current_trial_info['y_test'] = y_test\n",
    "        current_trial_info['y_test_pred'] = grid.predict(X_test)\n",
    "        current_trial_info['cv_results'] = grid.cv_results_\n",
    "        \n",
    "        trial_results.append(current_trial_info)\n",
    "        print(f'Completed trial {i}')\n",
    "        \n",
    "    return trial_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 1\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "Completed trial 1\n",
      "Running trial 2\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "Completed trial 2\n",
      "Running trial 3\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "Completed trial 3\n",
      "Running trial 4\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "Completed trial 4\n",
      "Running trial 5\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "Completed trial 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "hyperparameters = {\n",
    "    'randomforestclassifier__max_depth': [1,3,10,30,100],\n",
    "    # 'randomforestclassifier__max_samples': [0.25,0.5,0.75],\n",
    "    'randomforestclassifier__max_features': [0.25,0.5,0.75]\n",
    "} \n",
    "\n",
    "results_rfc = group_ml_pipe(X, y, groups, preprocessor=None, model=RandomForestClassifier(class_weight='balanced'), \n",
    "                        param_grid=hyperparameters, scoring_metric='f1_macro', \n",
    "                        num_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/rfc_results_classweighted.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(results_rfc, '../results/rfc_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n",
    "import xgboost\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "def xgb_classifier(X, y_cat, groups, preprocessor, param_grid, n_random_states=5):\n",
    "    output = {}\n",
    "    output['X_test'] = []\n",
    "    output['X_test_transformed'] = []\n",
    "    output['y_test_true'] = []\n",
    "    output['y_test_pred'] = []\n",
    "    output['test_scores_acc'] = []\n",
    "    output['test_scores_macro_f1'] = []\n",
    "    output['best_models'] = []\n",
    "\n",
    "    # Explicitly encode y\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = pd.Series(label_encoder.fit_transform(y_cat))\n",
    "\n",
    "    output['y_cat'] = y_cat\n",
    "    output['y'] = y\n",
    "    output['label_encoder'] = label_encoder\n",
    "\n",
    "    pg = ParameterGrid(param_grid)\n",
    "\n",
    "    trial_results = []\n",
    "\n",
    "    for state in range(n_random_states):\n",
    "        print(f\"\\n===== Random State: {state + 1} =====\")\n",
    "\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=state)\n",
    "        for train_val_idx, test_idx in gss.split(X, y, groups):\n",
    "            # print('TRAIN_VAL:', len(train_val_idx), 'TEST:', len(test_idx))\n",
    "            \n",
    "            X_train_val = X.iloc[train_val_idx]\n",
    "            y_train_val = y.iloc[train_val_idx]\n",
    "            groups_train_val = groups[train_val_idx]\n",
    "\n",
    "            X_test = X.iloc[test_idx]\n",
    "            y_test = y.iloc[test_idx]\n",
    "\n",
    "        test_scores = []\n",
    "        scores = np.zeros((len(pg),5))\n",
    "\n",
    "        for i, params in enumerate(pg):\n",
    "            print(f\"------- hyperparameter combination {i} -------\")\n",
    "            sgkf = StratifiedGroupKFold(n_splits=5)\n",
    "            for j, (train_idx, val_idx) in enumerate(sgkf.split(X_train_val, y_train_val, groups_train_val)):\n",
    "                print(f\"Fold {j + 1}\")\n",
    "\n",
    "                X_train, y_train = X_train_val.iloc[train_idx], y_train_val.iloc[train_idx]\n",
    "                X_CV, y_CV = X_train_val.iloc[val_idx], y_train_val.iloc[val_idx]\n",
    "\n",
    "                # Preprocess the data\n",
    "                X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "                X_CV_transformed = preprocessor.transform(X_CV)\n",
    "                X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "                # classes_weights = class_weight.compute_sample_weight(\n",
    "                #     class_weight='balanced',\n",
    "                #     y=y_train\n",
    "                # )\n",
    "\n",
    "                model = xgboost.XGBClassifier(**params, n_jobs=-1, objective='multi:softprob', early_stopping_rounds=50)\n",
    "                model.fit(\n",
    "                    X_train_transformed, y_train,\n",
    "                    eval_set=[(X_CV_transformed, y_CV)],\n",
    "                    verbose=False,\n",
    "                    # sample_weight=classes_weights\n",
    "                )\n",
    "                y_CV_pred = model.predict(X_CV_transformed)\n",
    "                scores[i][j] = f1_score(y_CV, y_CV_pred, average='macro')\n",
    "\n",
    "        scores = np.mean(scores, axis=1)\n",
    "        best_params = np.array(pg)[scores == np.max(scores)]\n",
    "\n",
    "        print('Val set max score and best parameters are:')\n",
    "        print(np.max(scores))\n",
    "        print(best_params)\n",
    "\n",
    "        # Train the model with best parameters and test on the test set\n",
    "        best_model = xgboost.XGBClassifier(**best_params[0], n_jobs=-1, early_stopping_rounds=50)\n",
    "        best_model.fit(\n",
    "            X_train_transformed, y_train,\n",
    "            eval_set=[(X_CV_transformed, y_CV)],\n",
    "            verbose=False\n",
    "        )\n",
    "        output['best_models'].append(best_model)\n",
    "        y_test_pred_best = best_model.predict(X_test_transformed)\n",
    "        output['X_test'].append(X_test)\n",
    "        output['X_test_transformed'].append(X_test_transformed)\n",
    "        output['y_test_true'].append(pd.Series(y_test))\n",
    "        output['y_test_pred'].append(pd.Series(y_test_pred_best))\n",
    "        test_score = f1_score(y_test, y_test_pred_best, average='macro')\n",
    "        output['test_scores_macro_f1'].append(test_score)\n",
    "        output['test_scores_acc'].append(accuracy_score(y_test, y_test_pred_best))\n",
    "\n",
    "    print('===============================================================================================')\n",
    "    print(f\"mean test macro f1: {np.mean(output['test_scores_macro_f1'])*100:.2f}% +/- {np.std(output['test_scores_macro_f1'])*100:.2f}%\")\n",
    "    print('===============================================================================================')\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Random State: 1 =====\n",
      "------- hyperparameter combination 0 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 1 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 2 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 3 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 4 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 5 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 6 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 7 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 8 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 9 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 10 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 11 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 12 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 13 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 14 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 15 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 16 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 17 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 18 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 19 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 20 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 21 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 22 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 23 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 24 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Val set max score and best parameters are:\n",
      "0.8602637848851149\n",
      "[{'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 10, 'missing': nan, 'n_estimators': 300, 'seed': 0, 'subsample': 0.66}]\n",
      "\n",
      "===== Random State: 2 =====\n",
      "------- hyperparameter combination 0 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 1 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 2 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 3 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 4 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 5 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 6 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 7 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 8 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 9 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 10 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 11 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 12 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 13 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 14 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 15 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 16 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 17 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 18 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 19 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 20 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 21 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 22 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 23 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 24 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Val set max score and best parameters are:\n",
      "0.8493692405466952\n",
      "[{'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 3, 'missing': nan, 'n_estimators': 1000, 'seed': 0, 'subsample': 0.66}]\n",
      "\n",
      "===== Random State: 3 =====\n",
      "------- hyperparameter combination 0 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 1 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 2 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 3 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 4 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 5 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 6 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 7 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 8 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 9 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 10 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 11 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 12 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 13 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 14 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 15 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 16 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 17 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 18 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 19 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 20 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 21 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 22 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 23 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 24 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Val set max score and best parameters are:\n",
      "0.8177226127189796\n",
      "[{'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 3, 'missing': nan, 'n_estimators': 1000, 'seed': 0, 'subsample': 0.66}]\n",
      "\n",
      "===== Random State: 4 =====\n",
      "------- hyperparameter combination 0 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 1 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 2 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 3 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 4 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 5 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 6 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 7 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 8 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 9 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 10 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 11 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 12 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 13 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 14 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 15 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 16 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 17 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 18 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 19 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 20 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 21 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 22 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 23 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 24 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Val set max score and best parameters are:\n",
      "0.8730500645127786\n",
      "[{'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 3, 'missing': nan, 'n_estimators': 1000, 'seed': 0, 'subsample': 0.66}]\n",
      "\n",
      "===== Random State: 5 =====\n",
      "------- hyperparameter combination 0 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 1 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 2 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 3 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 4 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 5 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 6 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 7 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 8 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 9 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 10 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 11 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 12 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 13 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 14 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 15 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 16 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 17 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 18 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 19 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 20 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 21 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 22 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 23 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "------- hyperparameter combination 24 -------\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Val set max score and best parameters are:\n",
      "0.8678826141703244\n",
      "[{'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 10, 'missing': nan, 'n_estimators': 1000, 'seed': 0, 'subsample': 0.66}]\n",
      "===============================================================================================\n",
      "mean test macro f1: 84.93% +/- 1.16%\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Replace `UserWarning` with the specific warning type\n",
    "\n",
    "hyperparameters = {\"learning_rate\": [0.03],\n",
    "                \"n_estimators\": [1,30,100,300,1000],\n",
    "                \"seed\": [0],\n",
    "                # \"clf_alpha\": [0e0, 1e-2, 1e-1, 1e0],\n",
    "                # \"clf_lambda\": [0e0, 1e-2, 1e-1, 1e0],\n",
    "                \"missing\": [np.nan], \n",
    "                \"max_depth\": [1,3,10,30,100],\n",
    "                \"colsample_bytree\": [0.9],              \n",
    "                \"subsample\": [0.66]}\n",
    "\n",
    "# Update pipeline call with the encoded target\n",
    "xgb_results = xgb_classifier(X=X, y_cat=y, groups=groups, preprocessor=StandardScaler(), \n",
    "                        param_grid=hyperparameters, n_random_states=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8472201889468266,\n",
       " 0.8506257347560007,\n",
       " 0.8533683680782541,\n",
       " 0.8297176307535233,\n",
       " 0.8654741748746682]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results['test_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8472201889468266,\n",
       " 0.8506257347560007,\n",
       " 0.8533683680782541,\n",
       " 0.8297176307535233,\n",
       " 0.8654741748746682]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be the same as previous cell - CHECK\n",
    "\n",
    "xgb_results['test_scores_macro_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_results, '../results/final/xgb_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 1\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "Completed trial 1\n",
      "Running trial 2\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "Completed trial 2\n",
      "Running trial 3\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "Completed trial 3\n",
      "Running trial 4\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "Completed trial 4\n",
      "Running trial 5\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "Completed trial 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "alpha_arr = np.logspace(-5,5,11,base=10)\n",
    "\n",
    "hyperparameters = {\n",
    "    'logisticregression__C': 1/alpha_arr,\n",
    "    'logisticregression__penalty':['l2'],\n",
    "    'logisticregression__max_iter':[10000],\n",
    "    'logisticregression__multi_class':['multinomial'],\n",
    "    'logisticregression__solver':['lbfgs']\n",
    "}\n",
    "\n",
    "results_lr = group_ml_pipe(X, y, groups, preprocessor=None, model=LogisticRegression(class_weight='balanced'), \n",
    "                        param_grid=hyperparameters, scoring_metric='f1_macro', \n",
    "                        num_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/logreg_results_classweighted.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(results_lr, '../results/logreg_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 1\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed trial 1\n",
      "Running trial 2\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed trial 2\n",
      "Running trial 3\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed trial 3\n",
      "Running trial 4\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed trial 4\n",
      "Running trial 5\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed trial 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "hyperparameters = { 'kneighborsclassifier__n_neighbors' : [1,30,100,300,1000],\n",
    "               'kneighborsclassifier__weights' : ['uniform','distance'],\n",
    "               'kneighborsclassifier__metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "results_knn = group_ml_pipe(X, y, groups, preprocessor=None, model=KNeighborsClassifier(), \n",
    "                        param_grid=hyperparameters, scoring_metric='f1_macro', \n",
    "                        num_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/knn_results.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(results_knn, '../results/knn_results.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
